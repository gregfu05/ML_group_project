{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook we will be training a Random Forest to predict the scorline of EPL games using the existing pipeline pipeline_ex_RandomForest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Import and Data Prep\n",
    "\n",
    "We import the necessary libraries and get the training, validation and testing datasets. These sets have undergone cleaning, preparation and feature engeneering in the original pipeline file, so they are ready to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- NaN Check before scaling ---\n",
      "NaNs in X_train: 0\n",
      "NaNs in X_val: 0\n",
      "NaNs in X_test: 0\n",
      "--- NaN Check after scaling ---\n",
      "NaNs in X_train_scaled: 0\n",
      "NaNs in X_val_scaled: 0\n",
      "NaNs in X_test_scaled: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikol\\Documents\\ML\\ML_group_project\\pipeline_ex_RandomForest.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  db['odds_hw'] = db[home_win_cols].mean(axis=1)\n",
      "c:\\Users\\nikol\\Documents\\ML\\ML_group_project\\pipeline_ex_RandomForest.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  db['odds_d']  = db[draw_cols].mean(axis=1)\n",
      "c:\\Users\\nikol\\Documents\\ML\\ML_group_project\\pipeline_ex_RandomForest.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  db['odds_aw'] = db[away_win_cols].mean(axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Evaluation Notebook\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sys, os\n",
    "\n",
    "# Import pipeline and load data\n",
    "sys.path.append(os.path.abspath('..'))  # Adjust if needed\n",
    "from pipeline_ex_RandomForest import get_train_val_test_data\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = get_train_val_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train type: <class 'pandas.core.frame.DataFrame'>\n",
      "X_train shape: (2410, 181)\n",
      "y_train type: <class 'pandas.core.frame.DataFrame'>\n",
      "y_train shape: (2410, 2)\n",
      "First 5 y_train columns: ['FTHG', 'FTAG']\n",
      "First 5 X_train columns: ['HTHG', 'HTAG', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR', 'Bb1X2', 'BbMxH', 'BbAvH', 'BbMxD', 'BbAvD', 'BbMxA', 'BbAvA', 'BbOU', 'BbMx_2.5', 'BbAv_2.5', 'BbMx_2.5', 'BbAv_2.5', 'BbAH', 'BbAHh', 'BbMxAHH', 'BbAvAHH', 'BbMxAHA', 'BbAvAHA', 'B365_2.5', 'B365_2.5', 'P_2.5', 'P_2.5', 'Max_2.5', 'Max_2.5', 'Avg_2.5', 'Avg_2.5', 'AHh', 'B365AHH', 'B365AHA', 'PAHH', 'PAHA', 'MaxAHH', 'MaxAHA', 'AvgAHH', 'AvgAHA', 'B365C_2.5', 'B365C_2.5', 'PC_2.5', 'PC_2.5', 'MaxC_2.5', 'MaxC_2.5', 'AvgC_2.5', 'AvgC_2.5', 'AHCh', 'B365CAHH', 'B365CAHA', 'PCAHH', 'PCAHA', 'MaxCAHH', 'MaxCAHA', 'AvgCAHH', 'AvgCAHA', 'BFEH', 'BFED', 'BFEA', 'BFE_2.5', 'BFE_2.5', 'BFEAHH', 'BFEAHA', 'BFECH', 'BFECD', 'BFECA', 'BFEC_2.5', 'BFEC_2.5', 'BFECAHH', 'BFECAHA', 'odds_hw', 'odds_d', 'odds_aw', 'HomeTeam_ID', 'AwayTeam_ID', 'HomeTeam_Arsenal', 'HomeTeam_Aston_Villa', 'HomeTeam_Bournemouth', 'HomeTeam_Brentford', 'HomeTeam_Brighton', 'HomeTeam_Burnley', 'HomeTeam_Cardiff', 'HomeTeam_Chelsea', 'HomeTeam_Crystal_Palace', 'HomeTeam_Everton', 'HomeTeam_Fulham', 'HomeTeam_Huddersfield', 'HomeTeam_Leeds', 'HomeTeam_Leicester', 'HomeTeam_Liverpool', 'HomeTeam_Luton', 'HomeTeam_Manchester_City', 'HomeTeam_Manchester_United', 'HomeTeam_Newcastle_United', 'HomeTeam_Norwich', 'HomeTeam_Nottingham_Forest', 'HomeTeam_Sheffield_United', 'HomeTeam_Southampton', 'HomeTeam_Stoke', 'HomeTeam_Swansea', 'HomeTeam_Tottenham', 'HomeTeam_Watford', 'HomeTeam_West_Bromwich_Albion', 'HomeTeam_West_Ham', 'HomeTeam_Wolverhampton_Wanderers', 'AwayTeam_Arsenal', 'AwayTeam_Aston_Villa', 'AwayTeam_Bournemouth', 'AwayTeam_Brentford', 'AwayTeam_Brighton', 'AwayTeam_Burnley', 'AwayTeam_Cardiff', 'AwayTeam_Chelsea', 'AwayTeam_Crystal_Palace', 'AwayTeam_Everton', 'AwayTeam_Fulham', 'AwayTeam_Huddersfield', 'AwayTeam_Leeds', 'AwayTeam_Leicester', 'AwayTeam_Liverpool', 'AwayTeam_Luton', 'AwayTeam_Manchester_City', 'AwayTeam_Manchester_United', 'AwayTeam_Newcastle_United', 'AwayTeam_Norwich', 'AwayTeam_Nottingham_Forest', 'AwayTeam_Sheffield_United', 'AwayTeam_Southampton', 'AwayTeam_Stoke', 'AwayTeam_Swansea', 'AwayTeam_Tottenham', 'AwayTeam_Watford', 'AwayTeam_West_Bromwich_Albion', 'AwayTeam_West_Ham', 'AwayTeam_Wolverhampton_Wanderers', 'Referee_A_Madley', 'Referee_A_Marriner', 'Referee_A_Moss', 'Referee_A_Taylor', 'Referee_C_Kavanagh', 'Referee_C_Pawson', 'Referee_D_Bond', 'Referee_D_Coote', 'Referee_D_England', 'Referee_G_Scott', 'Referee_J_Brooks', 'Referee_J_Gillett', 'Referee_J_Moss', 'Referee_J_Smith', 'Referee_K_Friend', 'Referee_L_Mason', 'Referee_L_Probert', 'Referee_M_Atkinson', 'Referee_M_Dean', 'Referee_M_Jones', 'Referee_M_Oliver', 'Referee_M_Salisbury', 'Referee_N_Swarbrick', 'Referee_O_Langford', 'Referee_P_Bankes', 'Referee_P_Tierney', 'Referee_R_East', 'Referee_R_Jones', 'Referee_R_Madley', 'Referee_S_Attwell', 'Referee_S_Barrott', 'Referee_S_Hooper', 'Referee_S_Scott', 'Referee_T_Bramall', 'Referee_T_Harrington', 'Referee_T_Robinson']\n"
     ]
    }
   ],
   "source": [
    "# Check data types and shapes\n",
    "print(\"X_train type:\", type(X_train))\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train type:\", type(y_train))\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"First 5 y_train columns:\", y_train.columns.tolist())\n",
    "print(\"First 5 X_train columns:\", X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Hyperparameter Tuning\n",
    "\n",
    "We tune the hyperparemeters using GridSearchCV to get the optimal model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "Best parameters: {'estimator__max_depth': 7, 'estimator__max_features': 'sqrt', 'estimator__min_samples_leaf': 4, 'estimator__min_samples_split': 5, 'estimator__n_estimators': 200}\n",
      "Best CV score (neg RMSE): -1.0017834169136337\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning (on validation set)\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__max_depth': [3, 5, 7],\n",
    "    'estimator__min_samples_split': [2, 5, 10],\n",
    "    'estimator__min_samples_leaf': [1, 2, 4],\n",
    "    'estimator__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "base_model = MultiOutputRegressor(RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "grid = GridSearchCV(base_model, param_grid, cv=3, scoring='neg_root_mean_squared_error', verbose=2, n_jobs=-1)\n",
    "grid.fit(X_train.values, y_train.values)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV score (neg RMSE):\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Validation Evaluation\n",
    "\n",
    "We validate the model and see how it performs on the validation set. This should give us an idea of how it performs and if the hyperparameter optimization was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE (raw): 1.0117995682891507\n",
      "Validation RMSE (rounded): 1.1029900332225915\n",
      "Validation MAE (raw): 0.8054240133174153\n",
      "Validation MAE (rounded): 0.7774086378737541\n",
      "Validation R2 (raw): 0.41083261125668613\n",
      "Validation R2 (rounded): 0.3568044172563198\n"
     ]
    }
   ],
   "source": [
    "# Validation set evaluation with rounded predictions\n",
    "y_val_pred = grid.predict(X_val.values)\n",
    "y_val_pred_rounded = np.round(y_val_pred)  # Round predictions to nearest integer\n",
    "\n",
    "print(\"Validation RMSE (raw):\", mean_squared_error(y_val, y_val_pred))\n",
    "print(\"Validation RMSE (rounded):\", mean_squared_error(y_val, y_val_pred_rounded))\n",
    "print(\"Validation MAE (raw):\", mean_absolute_error(y_val, y_val_pred))\n",
    "print(\"Validation MAE (rounded):\", mean_absolute_error(y_val, y_val_pred_rounded))\n",
    "print(\"Validation R2 (raw):\", r2_score(y_val, y_val_pred))\n",
    "print(\"Validation R2 (rounded):\", r2_score(y_val, y_val_pred_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Retrain and Evaluate\n",
    "\n",
    "We can now retrain the model on the train+val sets to ensure it sees as many examples as possible while avoiding leakage by leaving the test set untouched. We will use the test set to evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain on train+val, test on test set\n",
    "X_trainval = pd.concat([X_train, X_val])\n",
    "y_trainval = pd.concat([y_train, y_val])\n",
    "final_model = MultiOutputRegressor(\n",
    "    RandomForestRegressor(\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        **{k.replace('estimator__', ''): v for k, v in grid.best_params_.items()}\n",
    "    )\n",
    ")\n",
    "final_model.fit(X_trainval.values, y_trainval.values)\n",
    "y_test_pred = final_model.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 - Evaluation Results\n",
    "\n",
    "Here we see the results of our testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE (raw): 0.9523432055437859\n",
      "Test RMSE (rounded): 1.0231788079470199\n",
      "Test MAE (raw): 0.7643898637404292\n",
      "Test MAE (rounded): 0.7317880794701986\n",
      "Test R2 (raw): 0.40087755157296473\n",
      "Test R2 (rounded): 0.35596463345828355\n"
     ]
    }
   ],
   "source": [
    "# Test set evaluation with rounded predictions\n",
    "y_test_pred = final_model.predict(X_test.values)\n",
    "y_test_pred_rounded = np.round(y_test_pred)  # Round predictions to nearest integer\n",
    "\n",
    "print(\"Test RMSE (raw):\", mean_squared_error(y_test, y_test_pred))\n",
    "print(\"Test RMSE (rounded):\", mean_squared_error(y_test, y_test_pred_rounded))\n",
    "print(\"Test MAE (raw):\", mean_absolute_error(y_test, y_test_pred))\n",
    "print(\"Test MAE (rounded):\", mean_absolute_error(y_test, y_test_pred_rounded))\n",
    "print(\"Test R2 (raw):\", r2_score(y_test, y_test_pred))\n",
    "print(\"Test R2 (rounded):\", r2_score(y_test, y_test_pred_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FTHG_true  FTHG_pred  FTHG_pred_rounded  FTAG_true  FTAG_pred  \\\n",
      "0          2   2.064010                2.0          2   1.223948   \n",
      "1          2   1.928646                2.0          2   1.386642   \n",
      "2          1   0.953295                1.0          1   2.237210   \n",
      "3          4   2.991334                3.0          2   0.767785   \n",
      "4          1   1.392233                1.0          1   0.963454   \n",
      "\n",
      "   FTAG_pred_rounded  \n",
      "0                1.0  \n",
      "1                1.0  \n",
      "2                2.0  \n",
      "3                1.0  \n",
      "4                1.0  \n"
     ]
    }
   ],
   "source": [
    "# Show predictions vs actuals with rounded predictions\n",
    "results = pd.DataFrame({\n",
    "    'FTHG_true': y_test['FTHG'].values,\n",
    "    'FTHG_pred': y_test_pred[:, 0],\n",
    "    'FTHG_pred_rounded': y_test_pred_rounded[:, 0],\n",
    "    'FTAG_true': y_test['FTAG'].values,\n",
    "    'FTAG_pred': y_test_pred[:, 1],\n",
    "    'FTAG_pred_rounded': y_test_pred_rounded[:, 1]\n",
    "})\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Visuals - Feature Importance\n",
    "\n",
    "We can see what features were the most important and had the most weight in the predictions of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 most important features:\n",
      "    feature  importance\n",
      "0      HTHG    0.220516\n",
      "4       HST    0.161437\n",
      "80  odds_hw    0.066009\n",
      "2        HS    0.051032\n",
      "82  odds_aw    0.047949\n",
      "57     AHCh    0.038952\n",
      "81   odds_d    0.028487\n",
      "40      AHh    0.024314\n",
      "3        AS    0.017409\n",
      "35    P_2.5    0.011196\n"
     ]
    }
   ],
   "source": [
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': final_model.estimators_[0].feature_importances_\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "print(feature_importance.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
